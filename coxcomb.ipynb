{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-read in the 2.Indices_Target.csv file\n",
    "-filter on the NA-s in the snapshot_target column\n",
    "-get the unique target nums\n",
    "'''\n",
    "\n",
    "filename='2.Indices_Target.csv'\n",
    "df_target=pd.read_csv(f'C:/Users/511232/Desktop/Scorecard_coxcomb/{filename}', dtype='str')\n",
    "\n",
    "#filter out the dataframe where snapshot_target is NA\n",
    "df_na=df_target[df_target['snapshot_target'].isna()].copy()\n",
    "target_num_NA=set(df_na['Target_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code\tColor\n",
    "0\t    Grey\n",
    "1\t    Red\n",
    "2\t    Yellow\n",
    "3\t    Green\n",
    "\n",
    "-the scorecard.xlsx file, filter on color ('Color Scheme'=0) & ('Gap'=blank) & ('target' in target_num_NA)\n",
    "-groupby ['geoareaname', 'target'] and apply a function that will take the average of 'Trend'\n",
    "-and standardize the result of the average to be between [-10;+10]\n",
    "formula=N= -10 + [(A+100)/10]\n",
    "'''\n",
    "\n",
    "filename='scorecard.xlsx'\n",
    "#read in the scorecard.xlsx\n",
    "df=pd.read_excel('C:/Users/511232/Desktop/Scorecard_coxcomb/scorecard.xlsx', dtype=str)\n",
    "df['Trend'] = df['Trend'].astype(float)\n",
    "\n",
    "#flag as 1 if (df['Color Scheme']=='0') & (df['Gap'].isna()) & (df['target'].isin(target_num_NA)) condition meets\n",
    "cond=(df['Color Scheme']=='0') & (df['Gap'].isna()) & (df['target'].isin(target_num_NA))\n",
    "df.loc[cond,'flag']=1\n",
    "\n",
    "#filter color scheme=0 & Gap=blank\n",
    "df_filtered=df[(df['Color Scheme']=='0') & (df['Gap'].isna()) & (df['target'].isin(target_num_NA))].copy()\n",
    "\n",
    "\n",
    "def process(d):\n",
    "    '''will calculate average trend and standardize the value'''\n",
    "    trend_avg=d['Trend'].mean()\n",
    "    trend_avg_standardized=-10+((trend_avg+100)/10)\n",
    "    return(trend_avg_standardized)\n",
    "\n",
    "#apply the function on the df_filtered\n",
    "standardized_df=pd.DataFrame(df_filtered.groupby(['geoareaname','target'],group_keys=False).apply(process))\n",
    "standardized_df.reset_index(drop=False, inplace=True)\n",
    "standardized_df.columns=['geoareaname','target','standardized_value']\n",
    "#add flag=1\n",
    "standardized_df['flag']=1\n",
    "\n",
    "#merge the standardized_df with df\n",
    "result=pd.merge(df,standardized_df, how='left', on=['geoareaname','target', 'flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-generate coxcomb color using the following benchmarks:\n",
    "if N is negative --> red, takes the value of 1\n",
    "if N is postive but less or equal to 5.33 --> yellow, takes the value of 2\n",
    "if N is greater than 5.33--> green, takes the value of 3\"\n",
    "'''\n",
    "condition=[result['standardized_value']<0,(result['standardized_value']>0) & (result['standardized_value']<=5.33), result['standardized_value']>5.33]\n",
    "colors=[1,2,3]\n",
    "result['calculated_color']=np.select(condition,colors, default=np.nan)\n",
    "\n",
    "result.to_excel('processed_file.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discover the cutoff point for Yemen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'year':range(2000,2024), 'val':[100,85,75,70,75,65,58,55,80,60,50,80,90,100,120,130,135,125,140,145,150,155,158,160]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cutoff year is :2008\n"
     ]
    }
   ],
   "source": [
    "'''get the percentages of False and True from the boolean df['val'].pct_change()>0\n",
    "b will be like the below\n",
    "0     False\n",
    "1     False\n",
    "2     False\n",
    "3     False\n",
    "4      True\n",
    "'''\n",
    "b=df['val'].pct_change()>0\n",
    "freq=b.value_counts(normalize=True)*100\n",
    "\n",
    "#check if True (or False) is between 45-65 %, that is if False and True are almost 50-50\n",
    "#then there is a possibility of one chunk fro the timeseries having monotonic percent change sign\n",
    "if (freq[True]>=45) & (freq[True]<=65):\n",
    "\n",
    "    #get the index for ix of the True (or False)\n",
    "    #ix will be like Int64Index([4, 8, 11, 12, 13, 14, 15, 16, 18, 19, 20], dtype='int64')\n",
    "    ix=b[b].index\n",
    "\n",
    "    '''\n",
    "    get the last index of ix where the differene bewteen the 2 datapoints indices is greater than 3\n",
    "    that is get the last index of the non-monotonic (more than 3 years in this case) datapoints\n",
    "    since ix is the indices of the strictly monotonic datapoints (either increasing or decreasing, one of those chunks)\n",
    "    '''\n",
    "    idx=[i for i in range(len(ix)-1) if ix[i+1]-ix[i]>=3]\n",
    "\n",
    "    if idx:\n",
    "        last_index=ix[idx[-1]]\n",
    "        print(f'the cutoff year is :{df[\"year\"][last_index]}')\n",
    "    else:\n",
    "        print('returned empty list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/511232/Desktop/Scorecard_coxcomb')\n",
    "df=pd.read_excel('data Yemen1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_on_series(d):\n",
    "    global idx\n",
    "    global ix\n",
    "    \n",
    "    #get the categories labels\n",
    "    k=list(d.name)\n",
    "    k=[str(i) for i in k]\n",
    "\n",
    "    #report on the columns/names used in groupby\n",
    "    c=groupby_vars\n",
    "    categ_name=dict(zip(c,k))\n",
    "\n",
    "    #update a dictionary that will track number of datapoints for each groupby dataframes\n",
    "    series_count_key=f'{len(d)} datapoints'\n",
    "    if series_count_key in series_count.keys():\n",
    "        series_count[series_count_key]+=1\n",
    "    else:\n",
    "        series_count[series_count_key]=1\n",
    "\n",
    "    if len(d)>=10:\n",
    "                        \n",
    "            '''\n",
    "            get the percentages of False and True from the boolean df['val'].pct_change()>0\n",
    "            b will be like the below\n",
    "            0     False\n",
    "            1     False\n",
    "            2     False\n",
    "            3     False\n",
    "            4      True\n",
    "            '''\n",
    "            #reset dataframe index\n",
    "            d.reset_index(inplace=True)\n",
    "            b=d['Value'].pct_change()>0\n",
    "            freq=b.value_counts(normalize=True)*100\n",
    "\n",
    "            '''check if True (or False) is between 45-65 %, that is if False and True are almost 50-50\n",
    "            then there is a possibility of one chunk from the timeseries having monotonic percent change sign'''\n",
    "            if (freq[True]>=45) & (freq[True]<=65):\n",
    "\n",
    "                '''get the index for ix of the True (or False)\n",
    "                ix will be like Int64Index([4, 8, 11, 12, 13, 14, 15, 16, 18, 19, 20], dtype='int64')'''\n",
    "                ix=b[b].index\n",
    "                cutoff_year=float(d[\"TimePeriod\"][ix[0]],0)\n",
    "    \n",
    "            result_per_serie.append({'series':s, 'categories':categ_name, 'number of data_points':len(d),'cutoff_year':cutoff_year})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "#remove these from groupby vars\n",
    "list_to_exclude=['BasePeriod', 'TimeCoverage', 'Time_Detail','LowerBound', 'UpperBound', 'FootNote','GeoInfoUrl', 'Source','Reporting Type', 'Sampling Stations']\n",
    "\n",
    "#get unique SERIES\n",
    "unique_series=list(df['SeriesCode'].unique())\n",
    "\n",
    "result_per_serie=[] #initialize for each unique series\n",
    "series_count={}     #it will count indicators count\n",
    "cutoff_years=[]\n",
    "\n",
    "for s in unique_series:\n",
    "    #get the dataframe with SERIES == s\n",
    "    df_s=df[df['SeriesCode']==s].copy()\n",
    "    #get rid of null columns\n",
    "    df_s.dropna(how='all',axis=1, inplace=True)\n",
    "    #get the groupby vars which is the column names to groupby with\n",
    "    cols=df_s.columns\n",
    "    cols=set(cols).difference(set(list_to_exclude))\n",
    "    groupby_vars=list(cols.difference({'TimePeriod', 'Value'}))\n",
    "    \n",
    "    # apply the function on the dataframe\n",
    "    df_s.groupby(groupby_vars, as_index=True).apply(report_on_series)\n",
    "\n",
    "\n",
    "#add the counter result to result_per_serie\n",
    "result_per_serie.append(series_count)\n",
    "\n",
    "#write it to a json file\n",
    "with open('report.json', 'w') as outfile:\n",
    "    json.dump(result_per_serie,outfile, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coxcomb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
