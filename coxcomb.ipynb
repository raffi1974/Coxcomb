{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-read in the 2.Indices_Target.csv file\n",
    "-filter on the NA-s in the snapshot_target column\n",
    "-get the unique target nums\n",
    "'''\n",
    "\n",
    "filename='2.Indices_Target.csv'\n",
    "df_target=pd.read_csv(f'C:/Users/511232/Desktop/Scorecard_coxcomb/{filename}', dtype='str')\n",
    "\n",
    "#filter out the dataframe where snapshot_target is NA\n",
    "df_na=df_target[df_target['snapshot_target'].isna()].copy()\n",
    "target_num_NA=set(df_na['Target_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code\tColor\n",
    "0\t    Grey\n",
    "1\t    Red\n",
    "2\t    Yellow\n",
    "3\t    Green\n",
    "\n",
    "-the scorecard.xlsx file, filter on color ('Color Scheme'=0) & ('Gap'=blank) & ('target' in target_num_NA)\n",
    "-groupby ['geoareaname', 'target'] and apply a function that will take the average of 'Trend'\n",
    "-and standardize the result of the average to be between [-10;+10]\n",
    "formula=N= -10 + [(A+100)/10]\n",
    "'''\n",
    "\n",
    "filename='scorecard.xlsx'\n",
    "#read in the scorecard.xlsx\n",
    "df=pd.read_excel('C:/Users/511232/Desktop/Scorecard_coxcomb/scorecard.xlsx', dtype=str)\n",
    "df['Trend'] = df['Trend'].astype(float)\n",
    "\n",
    "#flag as 1 if (df['Color Scheme']=='0') & (df['Gap'].isna()) & (df['target'].isin(target_num_NA)) condition meets\n",
    "cond=(df['Color Scheme']=='0') & (df['Gap'].isna()) & (df['target'].isin(target_num_NA))\n",
    "df.loc[cond,'flag']=1\n",
    "\n",
    "#filter color scheme=0 & Gap=blank\n",
    "df_filtered=df[(df['Color Scheme']=='0') & (df['Gap'].isna()) & (df['target'].isin(target_num_NA))].copy()\n",
    "\n",
    "\n",
    "def process(d):\n",
    "    '''will calculate average trend and standardize the value'''\n",
    "    trend_avg=d['Trend'].mean()\n",
    "    trend_avg_standardized=-10+((trend_avg+100)/10)\n",
    "    return(trend_avg_standardized)\n",
    "\n",
    "#apply the function on the df_filtered\n",
    "standardized_df=pd.DataFrame(df_filtered.groupby(['geoareaname','target'],group_keys=False).apply(process))\n",
    "standardized_df.reset_index(drop=False, inplace=True)\n",
    "standardized_df.columns=['geoareaname','target','standardized_value']\n",
    "#add flag=1\n",
    "standardized_df['flag']=1\n",
    "\n",
    "#merge the standardized_df with df\n",
    "result=pd.merge(df,standardized_df, how='left', on=['geoareaname','target', 'flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-generate coxcomb color using the following benchmarks:\n",
    "if N is negative --> red, takes the value of 1\n",
    "if N is postive but less or equal to 5.33 --> yellow, takes the value of 2\n",
    "if N is greater than 5.33--> green, takes the value of 3\"\n",
    "'''\n",
    "condition=[result['standardized_value']<0,(result['standardized_value']>0) & (result['standardized_value']<=5.33), result['standardized_value']>5.33]\n",
    "colors=[1,2,3]\n",
    "result['calculated_color']=np.select(condition,colors, default=np.nan)\n",
    "\n",
    "result.to_excel('processed_file.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discover the cutoff point for Yemen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2005</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  val\n",
       "0   2000  100\n",
       "1   2001   85\n",
       "2   2002   75\n",
       "3   2003   70\n",
       "4   2004   75\n",
       "5   2005   65\n",
       "6   2006   58\n",
       "7   2007   55\n",
       "8   2008   80\n",
       "9   2009   60\n",
       "10  2010   50\n",
       "11  2011   80\n",
       "12  2012   90\n",
       "13  2013  100\n",
       "14  2014  120\n",
       "15  2015  130\n",
       "16  2016  135\n",
       "17  2017  125\n",
       "18  2018  140\n",
       "19  2019  145\n",
       "20  2020  150\n",
       "21  2021  155\n",
       "22  2022  158\n",
       "23  2023  160"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'year':range(2000,2024), 'val':[100,85,75,70,75,65,58,55,80,60,50,80,90,100,120,130,135,125,140,145,150,155,158,160]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     58.333333\n",
       "False    41.666667\n",
       "Name: val, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the percentages of False and True\n",
    "b=df['val'].pct_change()>0\n",
    "b.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([4, 8, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23], dtype='int64')\n",
      "the cutoff indeex is :8\n"
     ]
    }
   ],
   "source": [
    "#get the indices of one of the chunks of False or True\n",
    "ix=b[b].index\n",
    "print(ix)\n",
    "\n",
    "idx=[i for i in range(len(ix)-1) if ix[i+1]-ix[i]>=3]\n",
    "\n",
    "if idx:\n",
    "    print(f'the cutoff indeex is :{ix[idx[-1]]}')\n",
    "else:\n",
    "    print('returned empty list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/511232/Desktop/Scorecard_coxcomb')\n",
    "df=pd.read_excel('data Yemen.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_on_series(d):\n",
    "    global groupby_vars\n",
    "    global s\n",
    "    global result_per_serie\n",
    "    global series_counter\n",
    "    global series_counter_2dp\n",
    "    global series_counter_3plusdp\n",
    "    global series_count\n",
    "\n",
    "    #get the categories labels\n",
    "    k=list(d.name)\n",
    "    k=[str(i) for i in k]\n",
    "\n",
    "    #report on the columns/names used in groupby\n",
    "    c=groupby_vars\n",
    "    categ_name=dict(zip(c,k))\n",
    "\n",
    "    #update a dictionary that will track number of datapoints for each groupby dataframes\n",
    "    series_count_key=f'{len(d)} datapoints'\n",
    "    if series_count_key in series_count.keys():\n",
    "        series_count[series_count_key]+=1\n",
    "    else:\n",
    "        series_count[series_count_key]=1\n",
    "\n",
    "    \n",
    "    if len(d)==0:\n",
    "        result_per_serie.append({'series':s, 'categories':categ_name, 'number of data_points':len(d)})\n",
    "    elif (len(d)>0) & (len(d)<=2):\n",
    "        result_per_serie.append({'series':s, 'categories':categ_name, 'number of data_points':len(d)})\n",
    "    else:\n",
    "        result_per_serie.append({'series':s, 'categories':categ_name, 'number of data_points':len(d)})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove these from groupby vars\n",
    "list_to_exclude=['BasePeriod', 'TimeCoverage', 'Time_Detail','LowerBound', 'UpperBound', 'FootNote','GeoInfoUrl', 'Source','Reporting Type', 'Sampling Stations']\n",
    "\n",
    "#get unique SERIES\n",
    "unique_series=list(df['SeriesCode'].unique())\n",
    "\n",
    "result_per_serie=[] #initialize for each unique series\n",
    "series_count={}     #it will count indicators count\n",
    "\n",
    "\n",
    "for s in unique_series:\n",
    "    #get the dataframe with SERIES == s\n",
    "    df_s=df[df['SeriesCode']==s].copy()\n",
    "    #get rid of null columns\n",
    "    df_s.dropna(how='all',axis=1, inplace=True)\n",
    "    #get the groupby vars which is the column names to groupby with\n",
    "    cols=df_s.columns\n",
    "    cols=set(cols).difference(set(list_to_exclude))\n",
    "    groupby_vars=list(cols.difference({'TimePeriod', 'Value'}))\n",
    "    \n",
    "    # apply Sen slope on the dataframe\n",
    "    df_s.groupby(groupby_vars, as_index=True).apply(report_on_series)\n",
    "\n",
    "\n",
    "\n",
    "#add the counter result to result_per_serie\n",
    "result_per_serie.append(series_count)\n",
    "\n",
    "#write it to a json file\n",
    "with open('report.json', 'w') as outfile:\n",
    "    json.dump(result_per_serie,outfile, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coxcomb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
